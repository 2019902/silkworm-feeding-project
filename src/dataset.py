# -*- coding: utf-8 -*-
"""Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ma438JEEW08CMDjnE1q8RicG-W2y4lUf
"""

import os
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision import transforms

from src.global import csv_path, data_root, input_size, batch_size

# Custom dataset
class SilkwormDataset(Dataset):
    def __init__(self, csv_path, root_dir, transform=None):
        self.df = pd.read_csv(csv_path)
        self.root = root_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img = Image.open(os.path.join(self.root, row['foto'])).convert('RGB')
        if self.transform:
            img = self.transform(img)
        label = int(row['classificazione'])
        return img, label

# Transforms
dataset_transform = transforms.Compose([
    transforms.Resize(input_size),
    transforms.ToTensor(),
])

# Dataset and split data
dataset = SilkwormDataset(csv_path, data_root, transform=dataset_transform)
train_size = int(0.8 * len(dataset))
val_size   = len(dataset) - train_size
train_ds, val_ds = random_split(dataset, [train_size, val_size])

dataloaders = {
    'train': DataLoader(train_ds, batch_size=batch_size, shuffle=True),
    'val':   DataLoader(val_ds,   batch_size=batch_size, shuffle=False)
}

# Dataloader for unsupervised clustering
dataloader = DataLoader(dataset, batch_size=8, shuffle=False)