# -*- coding: utf-8 -*-
"""Utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ma438JEEW08CMDjnE1q8RicG-W2y4lUf
"""

import torch
import torch.nn.functional as F
import torch.nn.utils.prune as prune
import copy
import numpy as np
from sklearn.metrics import silhouette_score

from src.global import device

# Early stopping
def early_stop(val_loss, best_val_loss, no_improve, model, path):
    if val_loss < best_val_loss - 1e-4:
        torch.save(model.state_dict(), path)
        return val_loss, 0
    else:
        return best_val_loss, no_improve + 1

# Pruning
def apply_pruning(model, amount):
    params = [(m, 'weight') for m in model.modules() if isinstance(m, (torch.nn.Conv2d, torch.nn.Linear))]
    prune.global_unstructured(params, prune.L1Unstructured, amount=amount)
    for m, _ in params:
        prune.remove(m, 'weight')
    return model

# Pruning Evaluation
def evaluate(model, loader):
    model.eval()
    correct = total = 0
    with torch.no_grad():
        for imgs, labels in loader:
            imgs, labels = imgs.to(device), labels.to(device)
            preds = model(imgs).argmax(dim=1)
            total += labels.size(0)
            correct += (preds == labels).sum().item()
    return 100 * correct / total

def clone_and_prune(orig_model, amount):
    """
    Create a deep copy of the original model and apply global unstructured pruning.
    """
    m = copy.deepcopy(orig_model)
    params = [(module, 'weight') for module in m.modules() if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear))]
    prune.global_unstructured(params, prune.L1Unstructured, amount=amount)
    for module, _ in params:
        prune.remove(module, 'weight')
    return m

# Feature extraction for unsupervised clustering and Sobel filter
def extract_features(model, x):
    x = model.stem(x)
    x = model.stage2(x)
    return x

def sobel_filter(imgs):
    device = imgs.device
    kernel_x = torch.tensor([[1, 0, -1],
                             [2, 0, -2],
                             [1, 0, -1]], dtype=torch.float32, device=device).reshape(1, 1, 3, 3)
    kernel_y = torch.tensor([[1, 2, 1],
                             [0, 0, 0],
                             [-1, -2, -1]], dtype=torch.float32, device=device).reshape(1, 1, 3, 3)

    B, C, H, W = imgs.shape
    edges = torch.zeros_like(imgs)

    for c in range(C):
        channel = imgs[:, c:c+1, :, :]
        grad_x = F.conv2d(channel, kernel_x, padding=1)
        grad_y = F.conv2d(channel, kernel_y, padding=1)
        grad = torch.sqrt(grad_x ** 2 + grad_y ** 2)
        edges[:, c:c+1, :, :] = grad

    return edges

# Clustering evaluation
def evaluate_segmentation_quality(features, labels, method_name):
    try:
        sil_score = silhouette_score(features, labels)
        counts = np.bincount(labels)
        cluster_balance = np.std(counts) / np.mean(counts)

        print(f"\n{method_name} Results:")
        print(f"  Silhouette Score: {sil_score:.4f}")
        print(f"  Clusters: {len(np.unique(labels))}")
        print(f"  Cluster Balance: {cluster_balance:.4f}")

        return {
            'silhouette_score': sil_score,
            'n_clusters': len(np.unique(labels)),
            'cluster_balance': cluster_balance
        }
    except Exception as e:
        print(f"Error in {method_name}: {e}")
        return None

def compare_methods(results_dict):
    print("\n" + "="*50)
    print("SEGMENTATION COMPARISON")
    print("="*50)
    best_method = max(
        ((m, r['silhouette_score']) for m, r in results_dict.items() if r),
        key=lambda x: x[1],
        default=(None, -1)
    )
    for m, r in results_dict.items():
        if r:
            print(f"{m:15} | Silhouette: {r['silhouette_score']:.4f} | Clusters: {r['n_clusters']:2d} | Balance: {r['cluster_balance']:.3f}")
    print("="*50)
    if best_method[0]:
        print(f"Best Method: {best_method[0]} (Score: {best_method[1]:.4f})")
    print("="*50)
    return best_method[0]